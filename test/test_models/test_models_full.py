from __future__ import print_function
from __future__ import absolute_import
from __future__ import division
import pytest
from mlreco.models import factories
from mlreco.main_funcs import process_config, prepare, train_loop
import os
import yaml
import sys
os.environ['CUDA_VISIBLE_DEVICES'] = ''


branch = {
    "parse_sparse3d_scn": {
        float: ["sparse3d_pcluster"],
        int: ["sparse3d_pcluster_semantics"]
    },
    "parse_sparse3d_scn_scales": {
        int: ["sparse3d_pcluster_semantics"]
    },
    "parse_cluster3d_scales": {
        int: ["cluster3d_pcluster", "sparse3d_pcluster", "particle_pcluster"]
    },
    "parse_particle_points": {
        int: ["sparse3d_pcluster", "particle_pcluster"]
    },
    "parse_cluster3d_clean": {
        int: ["cluster3d_pcluster", "sparse3d_pcluster", "particle_pcluster"]
    }
}


@pytest.mark.slow
def test_model_full(config_full, xfail_models):
    """
    Tests whether a model can be trained.
    Including parsers and trainval in the execution.

    Parameters
    ----------
    config: dict
        Generated by a fixture above, dummy config to allow networks to run.
        It is mostly empty, we rely on networks default config.
    """
    if config_full['model']['name'] in xfail_models:
        pytest.xfail("%s is expected to fail at the moment." % config_full['model']['name'])

    config = config_full
    model, criterion = factories.construct(config['model']['name'])
    net = model(config['model']['modules'])
    loss = criterion(config['model']['modules'])

    if not hasattr(net, "INPUT_SCHEMA"):
        pytest.skip('No test defined for network of %s' % config['model']['name'])

    if not hasattr(loss, "INPUT_SCHEMA"):
        pytest.skip('No test defined for criterion of %s' % config['model']['name'])

    # Setup configuration to have all necessary I/O keys
    config['iotool']['dataset']['schema'] = {}
    config['model']['network_input'] = []
    config['model']['loss_input'] = []
    for i, x in enumerate(net.INPUT_SCHEMA + loss.INPUT_SCHEMA):
        parser_name = x[0]
        parser_return_types = x[1]
        config['iotool']['dataset']['schema'][i] = [x[0]]
        for t in parser_return_types:
            config['iotool']['dataset']['schema'][i].extend(branch[parser_name][t])
        if i < len(net.INPUT_SCHEMA):
            config['model']['network_input'].append(i)
        else:
            config['model']['loss_input'].append(i)

    process_config(config)
    # Try opening LArCV data file
    try:
        handlers = prepare(config)
    except FileNotFoundError:
        pytest.skip('File not found to test the loader.')

    train_loop(handlers)
